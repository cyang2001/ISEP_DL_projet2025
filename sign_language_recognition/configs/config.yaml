# Main configuration file
# All paths are relative to the project root

defaults:
  - mode: default
  - model: data_preprocessing
  - wandb: wandb
  - _self_

# Global settings
project:
  name: "sign_language_recognition"
  version: "0.1.0"
  description: "Video Sign Language Recognition using Transformer and Pose Estimation"
  seed: 42

# System settings
system:
  log_level: "INFO"
  log_dir: "logs"
  save_dir: "saved_models"
  use_gpu: true
  num_workers: 4

# Model dispatch mapping
model_dispatch:
  # Format: "model_name": "module_path:function_name"
  data_preprocessor: "src.data_preprocessing:main"
  transformer_trainer: "src.transformer_training:main"
  skeleton_extractor: "src.skeleton_extraction:main"
  model_evaluator: "src.model_evaluation:main"
  feature_extractor: "src.feature_extraction:main"
  video_visualizer: "src.video_visualization:main"

# Data settings
data:
  dataset: "wlasl"  # Options: "wlasl", "ms-asl", "custom"
  data_dir: "data"
  raw_dir: "data/raw/WLASL"  #  Update to include the WLASL folder path
  processed_dir: "data/processed"
  # WLASL specific settings
  wlasl_json_path: "data/WLASL_v0.3.json"  # WLASL data set annotation file path
  missing_videos_log: "data/missing_videos.txt"  # Record missing video files
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15

hydra:
  run:
    dir: .
  output_subdir: null

  job:
    name: ${model.name}
    config:
      override_dirname:
        item_sep: _
        kv_sep: "-"
        exclude_keys:
          - experiment
          - resume
          - resume_from_checkpoint
    env_set:
      EXAMPLE_VAR: "example_value"
